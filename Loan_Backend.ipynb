{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c5b8bd-3d75-4f7a-8cfc-89073e4485f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://github.com/TitaniumPeroxide/AI-Tech-Challenge---Group-17'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(county_file_path):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(county_file_path, file_name)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/TitaniumPeroxide/AI-Tech-Challenge---Group-17'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openAI_apiKey\")\n",
    "\n",
    "county_file_path = \"./AI-Tech-Challenge---Group-17\"\n",
    "\n",
    "text_chunks = []\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "for file_name in os.listdir(county_file_path):\n",
    "    if file_name.lower().endswith(\".pdf\"):\n",
    "        file_path = os.path.join(county_file_path, file_name)\n",
    "        loader = PDFPlumberLoader(file_path)\n",
    "        doc = loader.load()\n",
    "        for page in doc:\n",
    "            page.metadata['file_path'] = file_path\n",
    "        text_chunks.extend(text_splitter.split_documents(doc))\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(text_chunks, embedding=embeddings)\n",
    "\n",
    "# --- Prompt Template ---\n",
    "template = \"\"\"You are a Credit Scoring Assistant tasked with evaluating an individual's creditworthiness...\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer: \"\"\"\n",
    "\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])\n",
    "\n",
    "memory = ConversationBufferWindowMemory(memory_key='chat_history', input_key='question', output_key='answer', return_messages=True, k=10)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever(search_type='similarity', search_kwargs={'k': 5}),\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    max_tokens_limit=2000,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_PROMPT}\n",
    ")\n",
    "\n",
    "class ResultScore(BaseModel):\n",
    "    score: int = Field(description=\"Based on the answer, pick the appropriate score\")\n",
    "    reason: str = Field(description=\"Explain why this score was given based on the answer.\")\n",
    "    eligability: bool = Field(description=\"Based on the answer, pick if the answer is eligible or not\")\n",
    "\n",
    "result_score_parser = PydanticOutputParser(pydantic_object=ResultScore)\n",
    "result_score_format_instructions = result_score_parser.get_format_instructions()\n",
    "\n",
    "def extract_score(answer_text):\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        template=\"Evaluate the following answer and assign a score along with the reason.\\n{format_instructions}\\n\\nAnswer:\\n{message_content}\"\n",
    "    )\n",
    "    formatted_prompt = prompt_template.format_prompt(\n",
    "        format_instructions=result_score_format_instructions,\n",
    "        message_content=answer_text\n",
    "    )\n",
    "    response = llm.invoke(formatted_prompt.to_messages())\n",
    "    return result_score_parser.parse(response.content)\n",
    "\n",
    "def generate_question_for_section(section):\n",
    "    # Dynamic prompt for generating a question based on section\n",
    "    prompt = f\"Given the section '{section}', generate a relevant question that could be asked to evaluate someone's creditworthiness. Ask simple and short questions.\"\n",
    "    \n",
    "    question = llm.invoke(prompt)\n",
    "    print(question)\n",
    "    answer = question.content\n",
    "    print(answer)\n",
    "    return answer\n",
    "\n",
    "@app.route('/get_question', methods=['POST'])\n",
    "def get_question():\n",
    "    data = request.json\n",
    "    section = data.get(\"section\")\n",
    "    \n",
    "    if not section:\n",
    "        return jsonify({\"error\": \"Section is required\"}), 400\n",
    "\n",
    "    # Generate a dynamic question based on the section\n",
    "    question = generate_question_for_section(section)\n",
    "    \n",
    "    return jsonify({\"question\": question})\n",
    "\n",
    "# --- API Route ---\n",
    "@app.route('/evaluate', methods=['POST'])\n",
    "def evaluate():\n",
    "    data = request.json\n",
    "    print(data)\n",
    "    section = data.get(\"section\")\n",
    "    question = data.get(\"question\")\n",
    "    answer = data.get(\"answer\")\n",
    "\n",
    "    if not all([section, question, answer]):\n",
    "        return jsonify({\"error\": \"Missing required fields: section, question, or answer\"}), 400\n",
    "\n",
    "    # full_prompt = f\"Evaluate the following section of: {section} having the question: {question} where the user answered: {answer}.\"\n",
    "    full_prompt = f\"Evaluate the following section of : {section} having the question of {question} where the user answered as {answer} answer and assign the score/points from the document along with the reason.\"\n",
    "    result_ans = conversation_chain.invoke(full_prompt)\n",
    "    print(result_ans['answer'])\n",
    "\n",
    "    try:\n",
    "        result = extract_score(result_ans['answer'])\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Scoring failed: {str(e)}\"}), 500\n",
    "\n",
    "    return jsonify({\n",
    "        \"section\": section,\n",
    "        \"answer\": answer,\n",
    "        \"score\": result.score,\n",
    "        \"reason\": result.reason,\n",
    "        \"eligability\": result.eligability\n",
    "    })\n",
    "\n",
    "# --- Run ---\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206371c3-fdea-43ee-8e73-6c19dd0cd9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
